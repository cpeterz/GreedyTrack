# Ultralytics YOLO ðŸš€, AGPL-3.0 license

from functools import partial
from pathlib import Path

import torch

from ultralytics.utils import IterableSimpleNamespace, yaml_load
from ultralytics.utils.checks import check_yaml
from .bot_sort import BOTSORT
from .byte_tracker import BYTETracker

# A mapping of tracker types to corresponding tracker classes
TRACKER_MAP = {"bytetrack": BYTETracker, "botsort": BOTSORT}


def on_predict_start(predictor: object, persist: bool = False) -> None:
    """
    åœ¨é¢„æµ‹å¼€å§‹æ—¶åˆå§‹åŒ–å¯¹è±¡è¿½è¸ªå™¨ã€‚
    Initialize trackers for object tracking during prediction.

    Args:
        predictorï¼šè¡¨ç¤ºè¦ä¸ºå…¶åˆå§‹åŒ–è¿½è¸ªå™¨çš„é¢„æµ‹å™¨å¯¹è±¡ã€‚
        persistï¼ˆå¯é€‰ï¼‰ï¼šä¸€ä¸ªå¸ƒå°”å‚æ•°ï¼ŒæŒ‡ç¤ºæ˜¯å¦åœ¨è¿½è¸ªå™¨å·²å­˜åœ¨æ—¶æŒä¹…åŒ–è¿½è¸ªå™¨ã€‚é»˜è®¤å€¼ä¸º Falseã€‚
        predictor (object): The predictor object to initialize trackers for.
        persist (bool, optional): Whether to persist the trackers if they already exist. Defaults to False.

    Raises:
        AssertionError: If the tracker_type is not 'bytetrack' or 'botsort'.
    """
    if hasattr(predictor, "trackers") and persist:  # è‹¥å·²æœ‰è¿½è¸ªå™¨ä¸”æŒä¹…åŒ–ï¼Œåˆ™æ— éœ€é‡æ–°åˆå§‹åŒ–
        return

    # ä»Ž predictor.args.tracker ä¸­èŽ·å–è¿½è¸ªå™¨é…ç½®ï¼Œå¹¶é€šè¿‡ check_yaml å‡½æ•°å¯¹å…¶è¿›è¡Œæ£€æŸ¥ã€‚
    tracker = check_yaml(predictor.args.tracker)
    cfg = IterableSimpleNamespace(**yaml_load(tracker))

    if cfg.tracker_type not in ["bytetrack", "botsort"]:
        raise AssertionError(f"Only 'bytetrack' and 'botsort' are supported for now, but got '{cfg.tracker_type}'")

    trackers = []
    # å¯¹äºŽæ¯ä¸ªé¢„æµ‹å™¨ä¸­çš„æ•°æ®æ‰¹æ¬¡ï¼Œæ ¹æ®é…ç½®ä¸­çš„ tracker_type é€‰æ‹©ç›¸åº”çš„è¿½è¸ªå™¨ç±»è¿›è¡Œåˆå§‹åŒ–ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ° trackers åˆ—è¡¨ä¸­ã€‚
    for _ in range(predictor.dataset.bs):
        tracker = TRACKER_MAP[cfg.tracker_type](args=cfg, frame_rate=30)
        trackers.append(tracker)
    predictor.trackers = trackers


def on_predict_postprocess_end(predictor: object, persist: bool = False) -> None:
    """
    Postprocess detected boxes and update with object tracking.

    Args:
        predictor (object): The predictor object containing the predictions.
        persist (bool, optional): Whether to persist the trackers if they already exist. Defaults to False.
    """
    bs = predictor.dataset.bs
    path, im0s = predictor.batch[:2]

    is_obb = predictor.args.task == "obb"
    for i in range(bs):
        # å¦‚æžœä¸éœ€è¦æŒä¹…åŒ–è¿½è¸ªå™¨ä¸”å½“å‰è§†é¢‘è·¯å¾„ä¸Žä¸Šä¸€å¸§ä¸åŒï¼Œåˆ™é‡ç½®è¿½è¸ªå™¨ï¼Œä»¥å¤„ç†æ–°çš„è§†é¢‘ã€‚
        if not persist and predictor.vid_path[i] != str(predictor.save_dir / Path(path[i]).name):  # new video
            predictor.trackers[i].reset()

        # èŽ·å–å½“å‰å¸§çš„æ£€æµ‹ç»“æžœï¼ˆdetï¼‰ï¼Œå¦‚æžœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ï¼Œåˆ™ç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£ã€‚

        det = (predictor.results[i].obb if is_obb else predictor.results[i].boxes).cpu().numpy()
        if len(det) == 0:
            continue

        # ä½¿ç”¨è¿½è¸ªå™¨æ›´æ–°æ£€æµ‹ç»“æžœï¼Œå¾—åˆ°æ›´æ–°åŽçš„è·Ÿè¸ªç»“æžœ
        tracks = predictor.trackers[i].update(det, im0s[i])  # æ›´æ–°
        if len(tracks) == 0:
            continue
        idx = tracks[:, -1].astype(int)   # ä»Žè·Ÿè¸ªå™¨çš„è¾“å‡ºä¸­æå–äº†è·Ÿè¸ªç›®æ ‡çš„ç´¢å¼•
        predictor.results[i] = predictor.results[i][idx] # idx æ˜¯è·Ÿè¸ªå™¨è¿”å›žçš„ç´¢å¼•æ•°ç»„ï¼Œå®ƒæŒ‡ç¤ºäº†å½“å‰å¸§ä¸­æ¯ä¸ªç›®æ ‡åœ¨å‰ä¸€å¸§ä¸­çš„ç´¢å¼•ã€‚è¿™é‡Œæ˜¯åœ¨é‡æ–°æŽ’åº

        update_args = dict()
        update_args["obb" if is_obb else "boxes"] = torch.as_tensor(tracks[:, :-1])
        predictor.results[i].update(**update_args)




def register_tracker(model: object, persist: bool) -> None:
    """
    Register tracking callbacks to the model for object tracking during prediction.

    Args:
        model (object): The model object to register tracking callbacks for.
        persist (bool): Whether to persist the trackers if they already exist.
    """
    model.add_callback("on_predict_start", partial(on_predict_start, persist=persist))
    model.add_callback("on_predict_postprocess_end", partial(on_predict_postprocess_end, persist=persist))
