#.............................................................................................................................................................. Ultralytics YOLO ğŸš€, AGPL-3.0 license

import numpy as np

from .basetrack import BaseTrack, TrackState
from .utils import matching
from .utils.kalman_filter import KalmanFilterXYAH
from ..utils.ops import xywh2ltwh
from ..utils import LOGGER


class STrack(BaseTrack):
    """
    å•ä¸ªç›®æ ‡è·Ÿè¸ªçš„è¡¨ç¤ºç±»ï¼Œå®ƒä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢ï¼ˆKalman Filterï¼‰è¿›è¡ŒçŠ¶æ€ä¼°è®¡ã€‚
    Single object tracking representation that uses Kalman filtering for state estimation.

    This class is responsible for storing all the information regarding individual tracklets and performs state updates
    and predictions based on Kalman filter.

    Attributes:
        shared_kalman (KalmanFilterXYAH): å…±äº«çš„ Kalman æ»¤æ³¢å™¨ Shared Kalman filter that is used across all STrack instances for prediction.
        _tlwh (np.ndarray): ä¸€ä¸ªç§æœ‰å±æ€§ï¼Œå­˜å‚¨ç›®æ ‡è¾¹ç•Œæ¡†çš„å·¦ä¸Šè§’åæ ‡ã€å®½åº¦å’Œé«˜åº¦Private attribute to store top-left corner coordinates and width and height of bounding box.
        kalman_filter (KalmanFilterXYAH): ç”¨äºæ­¤å¯¹è±¡è·Ÿè¸ªçš„ Kalman æ»¤æ³¢å™¨å®ä¾‹Instance of Kalman filter used for this particular object track.
        mean (np.ndarray): çŠ¶æ€ä¼°è®¡å‘é‡çš„å‡å€¼Mean state estimate vector.
        covariance (np.ndarray):çŠ¶æ€ä¼°è®¡çš„åæ–¹å·®ã€‚Covariance of state estimate.
        is_activated (bool):å¸ƒå°”æ ‡å¿—ï¼ŒæŒ‡ç¤ºè·Ÿè¸ªæ˜¯å¦å·²æ¿€æ´»ã€‚ Boolean flag indicating if the track has been activated.
        score (float): è·Ÿè¸ªçš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚Confidence score of the track.
        tracklet_len (int): è·Ÿè¸ªé•¿åº¦ è¡¨ç¤ºè·Ÿè¸ªç›®æ ‡å·²ç»æŒç»­çš„å¸§æ•°ã€‚Length of the tracklet.
        cls (any):å¯¹è±¡çš„ç±»åˆ«æ ‡ç­¾ã€‚ Class label for the object.
        idx (int): å¯¹è±¡çš„ç´¢å¼•æˆ–æ ‡è¯†ç¬¦ã€‚Index or identifier for the object.
        frame_id (int): å½“å‰å¸§çš„ IDã€‚Current frame ID.
        start_frame (int): é¦–æ¬¡æ£€æµ‹åˆ°å¯¹è±¡çš„å¸§ã€‚Frame where the object was first detected.

    Methods:
        predict(): ä½¿ç”¨ Kalman æ»¤æ³¢å™¨é¢„æµ‹å¯¹è±¡çš„ä¸‹ä¸€ä¸ªçŠ¶æ€ Predict the next state of the object using Kalman filter.
        multi_predict(stracks): å¯¹ç»™å®šçš„å¤šä¸ª STrack å®ä¾‹æ‰§è¡Œå¤šå¯¹è±¡é¢„æµ‹è·Ÿè¸ªã€‚Predict the next states for multiple tracks.
        multi_gmc(stracks, H):ä½¿ç”¨å•åº”æ€§çŸ©é˜µæ›´æ–°å¤šä¸ªè·Ÿè¸ªçš„çŠ¶æ€ã€‚ Update multiple track states using a homography matrix.
        activate(kalman_filter, frame_id): æ¿€æ´»ä¸€ä¸ªæ–°çš„è·Ÿè¸ªã€‚Activate a new tracklet.
        re_activate(new_track, frame_id, new_id):ä½¿ç”¨æ–°æ£€æµ‹é‡æ–°æ¿€æ´»å…ˆå‰ä¸¢å¤±çš„è·Ÿè¸ªã€‚ Reactivate a previously lost tracklet.
        update(new_track, frame_id):æ›´æ–°åŒ¹é…è·Ÿè¸ªçš„çŠ¶æ€ã€‚ Update the state of a matched track.
        convert_coords(tlwh):  å°†è¾¹ç•Œæ¡†çš„æ ¼å¼ä»å·¦ä¸Šè§’-å®½åº¦-é«˜åº¦è½¬æ¢ä¸ºä¸­å¿ƒç‚¹-å®½åº¦-é«˜åº¦-è§’åº¦ã€‚Convert bounding box to x-y-aspect-height format.
        tlwh_to_xyah(tlwh): å°†è¾¹ç•Œæ¡†çš„æ ¼å¼ä»å·¦ä¸Šè§’-å®½åº¦-é«˜åº¦è½¬æ¢ä¸ºä¸­å¿ƒç‚¹-å®½åº¦-é«˜åº¦-è§’åº¦ã€‚Convert tlwh bounding box to xyah format.
    """

    shared_kalman = KalmanFilterXYAH()

    def __init__(self, xywh, score, cls):
        """Initialize new STrack instance."""
        super().__init__()
        # xywh+idx or xywha+idx
        assert len(xywh) in [5, 6], f"expected 5 or 6 values but got {len(xywh)}"
        self._tlwh = np.asarray(xywh2ltwh(xywh[:4]), dtype=np.float32)
        self.kalman_filter = None
        self.mean, self.covariance = None, None
        self.is_activated = False

        self.score = score
        self.tracklet_len = 0
        self.cls = cls
        self.idx = xywh[-1]
        self.angle = xywh[4] if len(xywh) == 6 else None

        #!!!!!
        self.keep_tracked = 0
        self.keep_lost = 0
        self.lost = 0
        #!!!!!

    def predict(self):
        """ç”¨äºä½¿ç”¨ Kalman æ»¤æ³¢å™¨è¿›è¡ŒçŠ¶æ€é¢„æµ‹ã€‚ Predicts mean and covariance using Kalman filter."""
        mean_state = self.mean.copy()
        if self.state != TrackState.Tracked:
            mean_state[7] = 0 # å°†é€Ÿåº¦åˆ†é‡çš„å‡å€¼è®¾ä¸ºé›¶æ¥æŠ‘åˆ¶é¢„æµ‹çš„é€Ÿåº¦ï¼Œä»¥ä¾¿æ›´å¥½åœ°å¤„ç†ä¸¢å¤±çš„è·Ÿè¸ªè½¨è¿¹ã€‚
        self.mean, self.covariance = self.kalman_filter.predict(mean_state, self.covariance)

    @staticmethod
    def multi_predict(stracks):
        """Perform multi-object predictive tracking using Kalman filter for given stracks."""
        if len(stracks) <= 0:
            return
        multi_mean = np.asarray([st.mean.copy() for st in stracks])
        multi_covariance = np.asarray([st.covariance for st in stracks])
        for i, st in enumerate(stracks):
            if st.state != TrackState.Tracked:
                multi_mean[i][7] = 0
        multi_mean, multi_covariance = STrack.shared_kalman.multi_predict(multi_mean, multi_covariance)
        for i, (mean, cov) in enumerate(zip(multi_mean, multi_covariance)):
            stracks[i].mean = mean
            stracks[i].covariance = cov

    @staticmethod
    def multi_gmc(stracks, H=np.eye(2, 3)):
        """æ›´æ–°ä¸€ç»„ç›®æ ‡è·Ÿè¸ªçš„ä½ç½®å’Œåæ–¹å·®ï¼Œä»¥é€‚åº”ä¸åŒè§†è§’æˆ–å¹³é¢çš„ç›®æ ‡è·Ÿè¸ªéœ€æ±‚ã€‚
        é€šå¸¸ç”¨äºå¤šæ‘„åƒå¤´ç³»ç»Ÿä¸­ï¼Œç”¨äºå¤„ç†ä¸åŒæ‘„åƒå¤´ä¹‹é—´çš„è§†è§’å˜æ¢æˆ–è€…é€è§†å˜æ¢ã€‚
    Update state tracks positions and covariances using a homography matrix."""
        if len(stracks) > 0:
            multi_mean = np.asarray([st.mean.copy() for st in stracks])
            multi_covariance = np.asarray([st.covariance for st in stracks])

            R = H[:2, :2]
            R8x8 = np.kron(np.eye(4, dtype=float), R)
            t = H[:2, 2]

            for i, (mean, cov) in enumerate(zip(multi_mean, multi_covariance)):
                mean = R8x8.dot(mean)
                mean[:2] += t
                cov = R8x8.dot(cov).dot(R8x8.transpose())

                stracks[i].mean = mean
                stracks[i].covariance = cov

    def activate(self, kalman_filter, frame_id):
        """å¯åŠ¨ä¸€ä¸ªæ–°çš„è·Ÿè¸ªè½¨è¿¹ã€‚ Start a new tracklet."""
        self.kalman_filter = kalman_filter
        self.track_id = self.next_id()
        self.mean, self.covariance = self.kalman_filter.initiate(self.convert_coords(self._tlwh))

        self.tracklet_len = 0
        self.state = TrackState.Tracked
        print("frame_id:", frame_id)
        if frame_id == 1:   ######ï¼ï¼ï¼ï¼ï¼ï¼ ä¸ºä»€ä¹ˆè¦åˆ¤æ–­æ¥æ¿€æ´»
            self.is_activated = True
        self.frame_id = frame_id
        self.start_frame = frame_id

    def re_activate(self, new_track, frame_id, new_id=False):
        """é‡æ–°æ¿€æ´»å…ˆå‰ä¸¢å¤±çš„è·Ÿè¸ªè½¨è¿¹ Reactivates a previously lost track with a new detection."""
        self.mean, self.covariance = self.kalman_filter.update(
            self.mean, self.covariance, self.convert_coords(new_track.tlwh)
        )
        self.tracklet_len = 0
        self.state = TrackState.Tracked
        self.is_activated = True
        self.frame_id = frame_id
        if new_id:
            self.track_id = self.next_id()
        self.score = new_track.score
        self.cls = new_track.cls
        self.angle = new_track.angle
        self.idx = new_track.idx

    def update(self, new_track, frame_id):
        """
        æ›´æ–°å·²åŒ¹é…è·Ÿè¸ªå¯¹è±¡çš„çŠ¶æ€ã€‚ä¿®æ­£å¡å°”æ›¼æ»¤æ³¢å™¨ï¼ˆå‡ç½®å’Œåæ–¹å·®ï¼‰
        Update the state of a matched track.

        Args:
            new_track (STrack): The new track containing updated information.
            frame_id (int): The ID of the current frame.
        """
        self.frame_id = frame_id
        self.tracklet_len += 1

        new_tlwh = new_track.tlwh
        self.mean, self.covariance = self.kalman_filter.update(
            self.mean, self.covariance, self.convert_coords(new_tlwh)
        )
        self.state = TrackState.Tracked
        self.is_activated = True

        self.score = new_track.score
        self.cls = new_track.cls
        self.angle = new_track.angle
        self.idx = new_track.idx

    def convert_coords(self, tlwh):
        """Convert a bounding box's top-left-width-height format to its x-y-aspect-height equivalent."""
        return self.tlwh_to_xyah(tlwh)

    @property
    def tlwh(self):
        """Get current position in bounding box format (top left x, top left y, width, height)."""
        if self.mean is None:
            return self._tlwh.copy()
        ret = self.mean[:4].copy()
        ret[2] *= ret[3]
        ret[:2] -= ret[2:] / 2
        return ret

    @property
    def xyxy(self):
        """Convert bounding box to format (min x, min y, max x, max y), i.e., (top left, bottom right)."""
        ret = self.tlwh.copy()
        ret[2:] += ret[:2]
        return ret

    @staticmethod
    def tlwh_to_xyah(tlwh):
        """Convert bounding box to format (center x, center y, aspect ratio, height), where the aspect ratio is width /
        height.
        """
        ret = np.asarray(tlwh).copy()
        ret[:2] += ret[2:] / 2
        ret[2] /= ret[3]
        return ret

    @property
    def xywh(self):
        """Get current position in bounding box format (center x, center y, width, height)."""
        ret = np.asarray(self.tlwh).copy()
        ret[:2] += ret[2:] / 2
        return ret

    @property
    def xywha(self):
        """Get current position in bounding box format (center x, center y, width, height, angle)."""
        if self.angle is None:
            LOGGER.warning("WARNING âš ï¸ `angle` attr not found, returning `xywh` instead.")
            return self.xywh
        return np.concatenate([self.xywh, self.angle[None]])

    @property
    def result(self):
        """Get current tracking results."""
        coords = self.xyxy if self.angle is None else self.xywha
        return coords.tolist() + [self.track_id, self.score, self.cls, self.idx]

    def __repr__(self):
        """Return a string representation of the BYTETracker object with start and end frames and track ID."""
        return f"OT_{self.track_id}_({self.start_frame}-{self.end_frame})"


class BYTETracker:
    """
    ä¸€ä¸ªåŸºäº YOLOv8 çš„ç›®æ ‡æ£€æµ‹å’Œè·Ÿè¸ªç®—æ³•ã€‚å®ƒè´Ÿè´£åˆå§‹åŒ–ã€æ›´æ–°å’Œç®¡ç†è§†é¢‘åºåˆ—ä¸­æ£€æµ‹åˆ°çš„å¯¹è±¡çš„è·Ÿè¸ªè½¨è¿¹ã€‚ä»¥ä¸‹æ˜¯è¿™ä¸ªç±»çš„ä¸€äº›é‡è¦å±æ€§å’Œæ–¹æ³•ï¼š
    BYTETracker: A tracking algorithm built on top of YOLOv8 for object detection and tracking.

    The class is responsible for initializing, updating, and managing the tracks for detected objects in a video
    sequence. It maintains the state of tracked, lost, and removed tracks over frames, utilizes Kalman filtering for
    predicting the new object locations, and performs data association.

    Attributes:
        tracked_stracks (list[STrack]): æˆåŠŸæ¿€æ´»çš„è·Ÿè¸ªè½¨è¿¹åˆ—è¡¨ã€‚ List of successfully activated tracks.
        lost_stracks (list[STrack]): ä¸¢å¤±çš„è·Ÿè¸ªè½¨è¿¹åˆ—è¡¨ã€‚ List of lost tracks.
        removed_stracks (list[STrack]): ç§»é™¤çš„è·Ÿè¸ªè½¨è¿¹åˆ—è¡¨ã€‚ List of removed tracks.
        frame_id (int): å½“å‰å¸§çš„ IDã€‚ The current frame ID.
        args (namespace): å‘½ä»¤è¡Œå‚æ•°ã€‚ Command-line arguments.
        max_time_lost (int): è¢«è®¤ä¸ºæ˜¯â€œä¸¢å¤±â€çš„è·Ÿè¸ªè½¨è¿¹çš„æœ€å¤§å¸§æ•°ã€‚ The maximum frames for a track to be considered as 'lost'.
        kalman_filter (object): ç”¨äºè·Ÿè¸ªè¾¹ç•Œæ¡†çš„å¡å°”æ›¼æ»¤æ³¢å™¨å¯¹è±¡ã€‚ Kalman Filter object.

    Methods:
        update(results, img=None):ä½¿ç”¨æ–°çš„æ£€æµ‹ç»“æœæ›´æ–°å¯¹è±¡è·Ÿè¸ªå™¨ï¼Œå¹¶è¿”å›è·Ÿè¸ªçš„å¯¹è±¡è¾¹ç•Œæ¡†ã€‚ Updates object tracker with new detections.
        get_kalmanfilter():è¿”å›ä¸€ä¸ªç”¨äºè·Ÿè¸ªè¾¹ç•Œæ¡†çš„å¡å°”æ›¼æ»¤æ³¢å™¨å¯¹è±¡ã€‚ Returns a Kalman filter object for tracking bounding boxes.
        init_track(dets, scores, cls, img=None): ä½¿ç”¨æ£€æµ‹å’Œåˆ†æ•°åˆå§‹åŒ–å¯¹è±¡è·Ÿè¸ªã€‚Initialize object tracking with detections.
        get_dists(tracks, detections): è®¡ç®—è·Ÿè¸ªå’Œæ£€æµ‹ä¹‹é—´çš„è·ç¦»ï¼Œä½¿ç”¨ IOU å¹¶èåˆåˆ†æ•°ã€‚Calculates the distance between tracks and detections.
        multi_predict(tracks):ä½¿ç”¨ YOLOv8 ç½‘ç»œè¿”å›é¢„æµ‹çš„è·Ÿè¸ªã€‚ Predicts the location of tracks.
        reset_id(): é‡ç½® STrack çš„ ID è®¡æ•°å™¨ã€‚Resets the ID counter of STrack.
        joint_stracks(tlista, tlistb): å°†ä¸¤ä¸ªè·Ÿè¸ªåˆ—è¡¨åˆå¹¶æˆä¸€ä¸ªã€‚Combines two lists of stracks.
        sub_stracks(tlista, tlistb): ä»ç¬¬ä¸€ä¸ªåˆ—è¡¨ä¸­ç­›é€‰å‡ºåœ¨ç¬¬äºŒä¸ªåˆ—è¡¨ä¸­ä¸å­˜åœ¨çš„è·Ÿè¸ªã€‚Filters out the stracks present in the second list from the first list.
        remove_duplicate_stracks(stracksa, stracksb): ï¼šåˆ é™¤é‡å¤çš„è·Ÿè¸ªè½¨è¿¹ï¼Œä½¿ç”¨éæœ€å¤§ IOU è·ç¦»ã€‚Removes duplicate stracks based on IOU.
    """

    def __init__(self, args, frame_rate=30):
        """Initialize a YOLOv8 object to track objects with given arguments and frame rate."""
        self.tracked_stracks = []  # type: list[STrack]
        self.lost_stracks = []  # type: list[STrack]
        self.removed_stracks = []  # type: list[STrack]

        ### !!!!!
        self.stracks = []  # type: list[STrack]
        self.track_id = -1
        ### !!!!!

        self.frame_id = 0
        self.args = args
        self.max_time_lost = int(frame_rate / 30.0 * args.track_buffer)
        self.kalman_filter = self.get_kalmanfilter()
        self.reset_id()
        self.debug = True

    def sort(self):
        self.stracks = sorted(self.stracks, key=lambda x: x.lost, reverse=True)

    def match(self, track, detections):
        dists = matching.iou_distance(track, detections)
        return dists


    def update(self, results, img=None):
        """Updates object tracker with new detections and returns tracked object bounding boxes."""
        print("new frame")
        self.frame_id += 1
        stracks = []

        # ä»æ£€æµ‹ç»“æœä¸­è·å–ç½®ä¿¡åº¦ã€è¾¹ç•Œæ¡†å’Œç±»åˆ«ä¿¡æ¯ã€‚
        scores = results.conf
        bboxes = results.xywhr if hasattr(results, "xywhr") else results.xywh
        bboxes = np.concatenate([bboxes, np.arange(len(bboxes)).reshape(-1, 1)], axis=-1)
        cls = results.cls
        if self.debug:
            print(f"frame_id:{self.frame_id}")
            print(f"bboxes:{bboxes} cls:{cls}")
            print(f"scores:{scores}")

        # æ ¹æ®é˜ˆå€¼å¯¹ç½®ä¿¡åº¦è¿›è¡Œç­›é€‰ï¼Œå¾—åˆ°ä¿ç•™çš„é«˜ç½®ä¿¡åº¦æ£€æµ‹æ¡†å’Œä½ç½®ä¿¡åº¦æ£€æµ‹æ¡†ã€‚
        high_thresh_index = scores > self.args.track_high_thresh
        inds_low = scores > self.args.track_low_thresh
        inds_high = scores < self.args.track_high_thresh
        low_thresh_index = np.logical_and(inds_low, inds_high)

        low_thresh_boxes = bboxes[low_thresh_index]        # ä½ç½®ä¿¡åº¦è§‚æµ‹è¾¹æ¡†
        high_thresh_boxes = bboxes[high_thresh_index]      # é«˜ç½®ä¿¡åº¦è§‚æµ‹è¾¹æ¡†
        high_thresh_score = scores[high_thresh_index]      # é«˜ç½®ä¿¡åº¦
        low_thresh_score = scores[low_thresh_index]        # ä½ç½®ä¿¡åº¦
        high_thresh_class = cls[high_thresh_index]         # é«˜ç½®ä¿¡åº¦ç±»åˆ«
        low_thresh_class = cls[low_thresh_index]           # ä½ç½®ä¿¡åº¦ç±»åˆ«

        if self.debug:
            print("low_thresh_boxes:", low_thresh_boxes)
            print("high_thresh_boxes:", high_thresh_boxes)
            print("high_thresh_score:", high_thresh_score)
            print("low_thresh_score:", low_thresh_score)
            print("high_thresh_class:", high_thresh_class)
            print("low_thresh_class:", low_thresh_class)

        # å°†é«˜ç½®ä¿¡åº¦æ£€æµ‹æ¡†åˆå§‹åŒ–ä¸ºè½¨è¿¹å¯¹è±¡ã€‚
        detections = self.init_track(high_thresh_boxes, high_thresh_score, high_thresh_class, img)
        print(f"lendetections:{len(detections)}")
        print(f"lentrackers:{len(self.stracks)}")

        if self.frame_id != 1:

            # å°†å½“å‰çš„è¿½è¸ªå™¨è‡ªè¡Œæ’åº
            self.sort()
            # å¯¹å½“å‰è¿½è¸ªå™¨è¿›è¡Œé¢„æµ‹
            self.multi_predict(self.stracks)

            print(f"end_multi_predict")

            # å°†è¿½è¸ªå™¨ä¾æ¬¡å’Œæ£€æµ‹æ¡†è¿›è¡ŒåŒ¹é…
            matched_tracks = []
            tracks = []
            for track in self.stracks:
                tracks.clear()
                tracks.append(track)
                dists = matching.iou_distance2(tracks, detections)
                # print(f"high_dists:{dists}")
                i = 0
                for dist in dists[0, :]:
                    print(f"high_dist:{dist}")
                    if len(detections) == 0:
                        # print("get no img")
                        break
                    if (len(dists) == 1 and dist < 1) or (dist < 0.95 and (dist + 0.05) < np.min(np.delete(dists, i))):
                        print("get high match")
                        # self.multi_predict(tracks)
                        track.update(detections[i], self.frame_id)
                        detections.pop(i)
                        matched_tracks.append(track)
                        break
                    i += 1
            unmatched_tracks = list(set(self.stracks) - set(matched_tracks))

            print(f"end_high_match")

            # å°†ä½ç½®ä¿¡åº¦çš„æ£€æµ‹æ¡†å’Œä¸æœªåŒ¹é…æˆåŠŸçš„è¿½è¸ªå™¨ç›¸åŒ¹é…
            detections_low = self.init_track(low_thresh_boxes, low_thresh_score, low_thresh_class, img)
            # åŒ¹é…æ–¹å¼ä¸ä¸Šé¢çš„ä¸€è‡´
            matched_tracks_low = []
            tracks2 = []
            for track in unmatched_tracks:
                tracks2.clear()
                tracks2.append(track)
                dists = matching.iou_distance2(tracks2, detections_low)
                # print(f"low_dists:{dists}")
                i = 0
                for dist in dists[0, :]:
                    print(f"low_dist:{dist}")
                    if len(detections_low) == 0:
                        # print("get no img")
                        break
                    if (len(dists) == 1 and dist < 1) or (dist < 0.95 and (dist + 0.05) < np.min(np.delete(dists, i))):
                        print("get low match")
                        # self.multi_predict(tracks)
                        track.update(detections_low[i], self.frame_id)
                        detections_low.pop(i)
                        matched_tracks_low.append(track)
                        break
                    i += 1
            unmatched_tracks_low = list(set(unmatched_tracks) - set(matched_tracks_low))

            print(f"end_low_match")

            # åŒ¹é…æˆåŠŸçš„æ”¾åˆ°ä¸€èµ·
            for track_list in [matched_tracks, matched_tracks_low]:
                for track in track_list:
                    track.keep_lost = 0
                    track.keep_tracked += 1
                    stracks.append(track)
                    print(f"matched_track_id:{track.track_id}")


            # å¦‚æœtrack_idåŒ¹é…æˆåŠŸï¼Œåˆ™ä¸æ›´æ–°ï¼Œå¦åˆ™è¿›è¡Œæ›´æ–°
            i = 0
            print(f"track id match strackslen:{len(stracks)}")
            for track in stracks:
                if track.track_id == self.track_id:
                    print("get track id")
                    stracks.insert(0, stracks.pop(i))
                    break
                i += 1

            # æ¸…ç©ºè¿½è¸ªå™¨å¹¶å°†å½“å‰åŒ¹é…æˆåŠŸçš„è¿½è¸ªå™¨æ”¾è¿›å»
            self.stracks.clear()
            for track in stracks:
                self.stracks.append(track)

            # ä¾ç„¶æ²¡æœ‰åŒ¹é…æˆåŠŸçš„trackæ ‡è®°ä¸ºlost++,è‹¥lostå¤§äºé˜ˆå€¼åˆ™åˆ é™¤è¯¥è¿½è¸ªå™¨
            for track in unmatched_tracks_low:
                track.keep_lost += 1
                track.keep_tracked = 0
                if track.keep_lost < 10:
                    self.stracks.append(track)
                else:
                    print(f"track{track.track_id} has been removed")

            # é«˜ç½®ä¿¡åº¦æ£€æµ‹æ¡†åˆå§‹åŒ–ä¸ºè½¨è¿¹
            for track in detections:
                track.activate(self.kalman_filter, self.frame_id)
                track.keep_lost = 0
                track.keep_tracked = track.keep_tracked + 1
                stracks.append(track)
                self.stracks.append(track)
        else:
            print(f"frame1: lendetections:{len(detections)}")
            if len(detections) > 0:
                for track in detections:
                    track.activate(self.kalman_filter, self.frame_id)
                    track.keep_lost = 0
                    track.keep_tracked = track.keep_tracked + 1
                    stracks.append(track)
                self.track_id = 1
                self.stracks = stracks
            else:
                print("no detection, frame_id --")
                self.frame_id = self.frame_id - 1

        # è®¡ç®— lost å€¼
        for track in self.stracks:
            track.lost = track.keep_tracked - track.keep_lost

        self.track_id = stracks[0].track_id if len(stracks) > 0 else self.track_id
        print(f"len(stracks):{len(stracks)}")
        print(f"len_selfstracks:{len(self.stracks)}")
        print(f"track_id:{self.track_id}")
        for track in self.stracks:
            print(f"self_track_id:{track.track_id}")
        return np.asarray([stracks[0].result] if len(stracks) > 0 else [], dtype=np.float32)


    def update2(self, results, img=None):
        """Updates object tracker with new detections and returns tracked object bounding boxes."""
        self.frame_id += 1
        activated_stracks = []
        refind_stracks = []
        lost_stracks = []
        removed_stracks = []

        # ä»æ£€æµ‹ç»“æœä¸­è·å–ç½®ä¿¡åº¦ã€è¾¹ç•Œæ¡†å’Œç±»åˆ«ä¿¡æ¯ã€‚
        scores = results.conf
        bboxes = results.xywhr if hasattr(results, "xywhr") else results.xywh
        # Add index
        bboxes = np.concatenate([bboxes, np.arange(len(bboxes)).reshape(-1, 1)], axis=-1)
        cls = results.cls

        # æ ¹æ®é˜ˆå€¼å¯¹ç½®ä¿¡åº¦è¿›è¡Œç­›é€‰ï¼Œå¾—åˆ°ä¿ç•™çš„é«˜ç½®ä¿¡åº¦æ£€æµ‹æ¡†å’Œä½ç½®ä¿¡åº¦æ£€æµ‹æ¡†ã€‚
        # ä½ç½®ä¿¡åº¦æŒ‡åœ¨track_low_threshå’Œtrack_high_threshä¹‹é—´çš„ç½®ä¿¡åº¦
        remain_inds = scores > self.args.track_high_thresh
        inds_low = scores > self.args.track_low_thresh
        inds_high = scores < self.args.track_high_thresh

        inds_second = np.logical_and(inds_low, inds_high)
        dets_second = bboxes[inds_second] # ä½ç½®ä¿¡åº¦è§‚æµ‹è¾¹æ¡†
        dets = bboxes[remain_inds]
        scores_keep = scores[remain_inds]
        scores_second = scores[inds_second]
        cls_keep = cls[remain_inds]
        cls_second = cls[inds_second]

        # å°†é«˜ç½®ä¿¡åº¦æ£€æµ‹æ¡†åˆå§‹åŒ–ä¸ºè½¨è¿¹å¯¹è±¡ã€‚
        detections = self.init_track(dets, scores_keep, cls_keep, img)
        # Add newly detected tracklets to tracked_stracks
        # å°†æœªæ¿€æ´»çš„è½¨è¿¹åŠ å…¥ unconfirmed åˆ—è¡¨ï¼Œå·²æ¿€æ´»çš„è½¨è¿¹åŠ å…¥ tracked_stracks åˆ—è¡¨ã€‚
        unconfirmed = []
        tracked_stracks = []  # type: list[STrack]
        for track in self.tracked_stracks:
            if not track.is_activated:
                unconfirmed.append(track)
            else:
                tracked_stracks.append(track)
        # Step 2: First association, with high score detection boxes
        # å°†å·²æ¿€æ´»çš„å’Œä¸¢å¤±çš„è½¨è¿¹æ± åˆå¹¶ã€‚
        strack_pool = self.joint_stracks(tracked_stracks, self.lost_stracks)

        # for track in self.tracked_stracks:
        #     if not track.is_activated:
        #         print("tracked_stracks is_activate:", track.track_id)
        #
        # for track in self.lost_stracks:
        #     if not track.is_activated:
        #         print("lost_stracks is_activate:", track.track_id)
        #
        # for track in self.removed_stracks:
        #     if not track.is_activated:
        #         print("removed_stracks is_activate:", track.track_id)


        # ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢å™¨é¢„æµ‹è½¨è¿¹æ± ä¸­å„ä¸ªè½¨è¿¹çš„å½“å‰ä½ç½®ã€‚ï¼ˆtracked+lostï¼‰
        self.multi_predict(strack_pool)

        # å¦‚æœå­˜åœ¨å›¾åƒå˜æ¢å™¨ (`gmc`) å¹¶ä¸”è¾“å…¥äº†å›¾åƒï¼Œåˆ™å¯¹æ£€æµ‹æ¡†è¿›è¡Œå‡ ä½•å˜æ¢
        if hasattr(self, "gmc") and img is not None:
            warp = self.gmc.apply(img, dets)
            STrack.multi_gmc(strack_pool, warp)
            STrack.multi_gmc(unconfirmed, warp)

        # è®¡ç®—è½¨è¿¹æ± ä¸­å„ä¸ªè½¨è¿¹ä¸é«˜ç½®ä¿¡åº¦æ£€æµ‹æ¡†ä¹‹é—´çš„è·ç¦»ã€‚
        dists = self.get_dists(strack_pool, detections)
        print(f"dists:{dists}")
        # dists2 = matching.iou_distance(strack_pool, detections)

        # è¾“å‡ºè·ç¦»å€¼å’Œç½®ä¿¡åº¦
        # for i, dist in enumerate(dists):
        #     print(f"ALL track {i} and detections: {dist}")
        # for i, dist in enumerate(dists2):
        #     print(f"IOU track {i} and detections: {dist}")
        # ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•è¿›è¡Œå…³è”åŒ¹é…ã€‚
        # matchesæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«äº†æˆåŠŸåŒ¹é…çš„è·Ÿè¸ªç›®æ ‡å’Œæ£€æµ‹ç»“æœçš„ç´¢å¼•å¯¹ã€‚
        # u_trackæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«äº†æœªåŒ¹é…çš„è·Ÿè¸ªç›®æ ‡çš„ç´¢å¼•ã€‚
        # u_detectionæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«äº†æœªåŒ¹é…çš„æ£€æµ‹ç»“æœçš„ç´¢å¼•ã€‚
        matches, u_track, u_detection = matching.linear_assignment(dists, thresh=self.args.match_thresh)

        # æ ¹æ®åŒ¹é…ç»“æœï¼Œæ›´æ–°å·²è·Ÿè¸ªçš„è½¨è¿¹çŠ¶æ€æˆ–é‡æ–°æ¿€æ´»ä¸¢å¤±çš„è½¨è¿¹
        for itracked, idet in matches:
            track = strack_pool[itracked]
            det = detections[idet]
            if track.state == TrackState.Tracked:
                track.update(det, self.frame_id)
                activated_stracks.append(track)
            else:
                track.re_activate(det, self.frame_id, new_id=False)
                refind_stracks.append(track)
        # Step 3: Second association, with low score detection boxes association the untrack to the low score detections

        # å°†ä½ç½®ä¿¡åº¦çš„æ£€æµ‹æ¡†å’Œä¸æœªåŒ¹é…çš„è¿½è¸ªå™¨ç›¸åŒ¹é…ï¼Œè¿™é‡ŒåªåšIOU_match
        detections_second = self.init_track(dets_second, scores_second, cls_second, img)
        r_tracked_stracks = [strack_pool[i] for i in u_track if strack_pool[i].state == TrackState.Tracked]
        # TODO
        dists = matching.iou_distance(r_tracked_stracks, detections_second)
        matches, u_track, u_detection_second = matching.linear_assignment(dists, thresh=0.5)

        # æ ¹æ®åŒ¹é…ç»“æœï¼Œæ›´æ–°å·²è·Ÿè¸ªçš„è½¨è¿¹çŠ¶æ€æˆ–é‡æ–°æ¿€æ´»ä¸¢å¤±çš„è½¨è¿¹
        for itracked, idet in matches:
            track = r_tracked_stracks[itracked]
            det = detections_second[idet]
            if track.state == TrackState.Tracked:
                track.update(det, self.frame_id)
                activated_stracks.append(track)
            else:
                track.re_activate(det, self.frame_id, new_id=False)
                refind_stracks.append(track)

        # æ²¡æœ‰åŒ¹é…æˆåŠŸçš„trackæ ‡è®°ä¸ºLost
        for it in u_track:
            track = r_tracked_stracks[it]
            if track.state != TrackState.Lost:
                track.mark_lost()
                lost_stracks.append(track)

        # Deal with unconfirmed tracks, usually tracks with only one beginning frame
        # å¤„ç†æœªæ¿€æ´»çš„è½¨è¿¹ï¼Œé€šå¸¸æ˜¯åªå‡ºç°äº†ä¸€å¸§çš„è½¨è¿¹ï¼Œè¿˜æœªä¸å…¶ä»–å¸§ç›®æ ‡ç›¸å…³è”ï¼Œè¿™é‡Œå°±è®©ä»–ä»¬å°è¯•å’Œè½é€‰çš„æ£€æµ‹ç›®æ ‡ç›¸å…³è”
        detections = [detections[i] for i in u_detection]
        dists = self.get_dists(unconfirmed, detections)
        matches, u_unconfirmed, u_detection = matching.linear_assignment(dists, thresh=0.7)
        for itracked, idet in matches:
            unconfirmed[itracked].update(detections[idet], self.frame_id)
            activated_stracks.append(unconfirmed[itracked])
        for it in u_unconfirmed:  # æœªæ¿€æ´»çš„æ²¡åŒ¹é…ä¸Šå°±Remove
            track = unconfirmed[it]
            track.mark_removed()
            removed_stracks.append(track)
        # Step 4: Init new stracks
        for inew in u_detection: # æ²¡æœ‰åŒ¹é…ä¸Šçš„ç›®æ ‡é«˜äºé˜ˆå€¼åˆ™æ–°å»ºä¸€ä¸ªtrack
            track = detections[inew]
            if track.score < self.args.new_track_thresh:
                continue
            track.activate(self.kalman_filter, self.frame_id)
            activated_stracks.append(track)
        # Step 5: Update state
        # lostè¶…è¿‡ä¸€å®šæ—¶é—´åˆ™remove
        for track in self.lost_stracks:
            if self.frame_id - track.end_frame > self.max_time_lost:
                track.mark_removed()
                removed_stracks.append(track)

        self.tracked_stracks = [t for t in self.tracked_stracks if t.state == TrackState.Tracked]
        self.tracked_stracks = self.joint_stracks(self.tracked_stracks, activated_stracks)
        self.tracked_stracks = self.joint_stracks(self.tracked_stracks, refind_stracks)
        self.lost_stracks = self.sub_stracks(self.lost_stracks, self.tracked_stracks)
        self.lost_stracks.extend(lost_stracks)
        self.lost_stracks = self.sub_stracks(self.lost_stracks, self.removed_stracks)
        self.tracked_stracks, self.lost_stracks = self.remove_duplicate_stracks(self.tracked_stracks, self.lost_stracks)
        self.removed_stracks.extend(removed_stracks)
        if len(self.removed_stracks) > 1000:
            self.removed_stracks = self.removed_stracks[-999:]  # clip remove stracks to 1000 maximum

        # print("frame_id:", self.frame_id)
        # for strack in self.tracked_stracks:
        #     print("Data in tracked_strack:")
        #     print("Track ID:", strack.track_id)
        #     print("Other state:", strack.state)
        #     print("Other score:", strack.score)

        return np.asarray([x.result for x in self.tracked_stracks if x.is_activated], dtype=np.float32)

    def get_kalmanfilter(self):
        """Returns a Kalman filter object for tracking bounding boxes."""
        return KalmanFilterXYAH()

    def init_track(self, dets, scores, cls, img=None):
        """Initialize object tracking with detections and scores using STrack algorithm."""
        return [STrack(xyxy, s, c) for (xyxy, s, c) in zip(dets, scores, cls)] if len(dets) else []  # detections

    def get_dists(self, tracks, detections):
        """Calculates the distance between tracks and detections using IOU and fuses scores."""
        dists = matching.iou_distance(tracks, detections)
        # TODO: mot20
        # if not self.args.mot20:
        # dists = matching.fuse_score(dists, detections)
        return dists

    def multi_predict(self, tracks):
        """Returns the predicted tracks using the YOLOv8 network."""
        STrack.multi_predict(tracks)

    @staticmethod
    def reset_id():
        """Resets the ID counter of STrack."""
        STrack.reset_id()

    def reset(self):
        """Reset tracker."""
        self.tracked_stracks = []  # type: list[STrack]
        self.lost_stracks = []  # type: list[STrack]
        self.removed_stracks = []  # type: list[STrack]
        self.frame_id = 0
        self.kalman_filter = self.get_kalmanfilter()
        self.reset_id()

    @staticmethod
    def joint_stracks(tlista, tlistb):
        """Combine two lists of stracks into a single one."""
        exists = {}
        res = []
        for t in tlista:
            exists[t.track_id] = 1
            res.append(t)
        for t in tlistb:
            tid = t.track_id
            if not exists.get(tid, 0):
                exists[tid] = 1
                res.append(t)
        return res

    @staticmethod
    def sub_stracks(tlista, tlistb):
        """DEPRECATED CODE in https://github.com/ultralytics/ultralytics/pull/1890/
        stracks = {t.track_id: t for t in tlista}
        for t in tlistb:
            tid = t.track_id
            if stracks.get(tid, 0):
                del stracks[tid]
        return list(stracks.values())
        """
        track_ids_b = {t.track_id for t in tlistb}
        return [t for t in tlista if t.track_id not in track_ids_b]

    @staticmethod
    def remove_duplicate_stracks(stracksa, stracksb):
        """Remove duplicate stracks with non-maximum IOU distance."""
        pdist = matching.iou_distance(stracksa, stracksb)
        pairs = np.where(pdist < 0.15)
        dupa, dupb = [], []
        for p, q in zip(*pairs):
            timep = stracksa[p].frame_id - stracksa[p].start_frame
            timeq = stracksb[q].frame_id - stracksb[q].start_frame
            if timep > timeq:
                dupb.append(q)
            else:
                dupa.append(p)
        resa = [t for i, t in enumerate(stracksa) if i not in dupa]
        resb = [t for i, t in enumerate(stracksb) if i not in dupb]
        return resa, resb
